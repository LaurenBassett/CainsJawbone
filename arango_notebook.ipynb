{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arango import ArangoClient\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arango import ArangoClient\n",
    "\n",
    "client = ArangoClient(hosts='http://127.0.0.1:8529')\n",
    "db = client.db('_system', username='root', password = 'openSesame')\n",
    "db.collections()\n",
    "pages = db.collection(\"Page\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "count_of_possible_solutions= math.factorial(100)\n",
    "print(count_of_possible_solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cain's Jawbone contains exactly 100 pages, printed out of order. Before doing any analysis of any kind, there are exactly 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000 possible solutions to the puzzle. \n",
    "\n",
    "I think it would be fun to estimate how long it would take to read all possible combinations of the puzzle as we move forward, so I am going to calculate a word count for each page, as well as for the entire book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count=0\n",
    "for i in range(1,100):\n",
    "    _id = \"Page/\" +str(i)\n",
    "    current_doc = db.document(_id)\n",
    "    text = current_doc['content'].strip()\n",
    "    x = [i.translate(i.maketrans(\"\", \"\", string.punctuation)).isalpha() for i in text.split(\" \")]  \n",
    "    word_count=sum(x)\n",
    "    current_doc['word_count'] = word_count\n",
    "    db.update_document(current_doc)\n",
    "    total_count+=word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_long_to_read(possible_solutions, wpm):\n",
    "    #The averageperson reads 238 words per minute.\n",
    "    minutes= possible_solutions*(total_count/wpm)\n",
    "    years = minutes/525600\n",
    "    millenia = years/1000\n",
    "\n",
    "    return(millenia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things I want to classify quickly is if I can determine the gender of the author. This will help me start to group like-authors together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9679370075067095e+147"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_time = how_long_to_read(count_of_possible_solutions,238)\n",
    "how_long_to_read(count_of_possible_solutions,1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So before doing any analytics at all, it will take the average person 1.24E151 Millennia to read all possible combinations. Even at 1,000,000 words per minute, it would take 2.96E147 millenia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe the first big thing I can do to lower the number of possible connections is to describe the beginning and ending conditions that may or may not connect pages together. I am iterating through each page, and determining the first and last character. From there, I assign a value based on the type of ending each page has. For example, pages that end with poems can only be linked with pages that start with poems. \n",
    "\n",
    "There are now 720 possible combinations of how these pages can line up together, which is still a lot, but utililzing the context clues and other information will help narrow down the choices. \n",
    "\n",
    "The same is true for the pages that start and end in the middle of sentences. \n",
    "\n",
    "The pages that start with I are a wild card, since I must always be capitalized, it is difficult to know if the pronoun occurs at the beginning or middle of a sentence, however, it still limits the number of pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page/66\n",
      "Page/67\n",
      "Page/73\n",
      "Page/74\n"
     ]
    }
   ],
   "source": [
    "incomplete_starts = 0\n",
    "incomplete_ends = 0\n",
    "poem_starts = 6\n",
    "poem_ends = 6\n",
    "starts_with_i = 0\n",
    "normal_starts = 0\n",
    "normal_ends = 0\n",
    "for i in range(1,100):\n",
    "    _id = \"Page/\" +str(i)\n",
    "    current_doc = db.document(_id)\n",
    "    passage = current_doc['content'].strip()\n",
    "    end = passage[-1]\n",
    "    if i in [12, 23, 41,49,86,92]:\n",
    "        current_doc['end_condition'] = 'poem starts on page'\n",
    "    elif end not in ['.','?', '!', '‚Äù']:\n",
    "        current_doc['end_condition'] = 'incomplete end'\n",
    "        incomplete_ends+=1\n",
    "        print(_id)\n",
    "    else: \n",
    "        current_doc['end_condition'] = \"None\"\n",
    "        normal_ends+=1\n",
    "\n",
    "    if i in [13, 24, 42,50,87,93]:\n",
    "        current_doc['start_condition'] = 'poem ends on page'\n",
    "    elif passage[0].islower():\n",
    "        current_doc['start_condition'] = 'incomplete beginning'\n",
    "        incomplete_starts+=1\n",
    "        print(_id)\n",
    "    else:\n",
    "        current_doc['start_condition'] = \"None\"\n",
    "        normal_starts+=1\n",
    "    db.update_document(current_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 pages: 66, 67, 73, and 74, that are most likely paired with each other, and 12 poems: 12, 23, 41,49,86,92, 13, 24, 42,50,87,93 that are also likely paired together in some way. \n",
    "\n",
    "This means that there are only 2 combinations to arrange the incomplete pages, and 6! (740) combinations that the pages containing the poems can be arranged. \n",
    "\n",
    "This does not account for the pages directly before or after these pairs, only the pairs themselves, which can still appear anywhere in the novel. \n",
    "\n",
    "However, we have 9 pages that have a limited number of predecessors. \n",
    "\n",
    "I think we cand decrease the total number of pages to:\n",
    "\n",
    "84! * 6! * 2! \n",
    "\n",
    "This has saved us a few millenia. We are now looking at 6.38E122 Millenia to read all possible combinations. Think of all the things you can get done now that you aren't wasting \n",
    "12470323560952561367028935412358888882412853902766811155097386706704162155279925109869007431432624370574548868995653362416626605197646505954304956825600.000000 millenia reading the wrong combination of Cain's Jawbone! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "After_end_analysis=math.factorial(84) * math.factorial(6)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_end_analysis_time = how_long_to_read(After_end_analysis, 238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12470323560952561367028935412358888882412853902766811155097386706704162155279925109869007431432624370574548868995653362416626605197646505954304956825600.000000'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_saved = init_time-after_end_analysis_time\n",
    "'{:f}'.format(time_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,100):\n",
    "    _id = \"Page/\" +str(i)\n",
    "    current_doc = db.document(_id)\n",
    "    print(\"\\t\\t\\t---------Page \",i,\"-----------\")\n",
    "    print(current_doc['content'])\n",
    "    ask = input(\"Is this MALE, FEMALE, or do you not know?\")\n",
    "    if ask != \"MALE\" or \"FEMALE\":\n",
    "        continue\n",
    "    else:\n",
    "        current_doc['gender'] = ask\n",
    "        db.update_document(current_doc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Page/1\"\n",
    "chage=db.document(doc)\n",
    "chage['key_words'].append(\"pen\")\n",
    "db.update_document(chage)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "619226f811c1a3cf24b57725644a3f9927ee4a52cb448157cb29be04a2ef885e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
